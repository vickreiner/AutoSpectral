---
title: "11 Speed It Up (Why So Slow?)"
output: html_document
date: "2026-01-18"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

AutoSpectral takes a lot longer to unmix files than standard OLS or WLS unmixing approaches. Most of that is because it's doing way more calculations. If we consider a 40-color panel with a million cells, there is essentially only a single computationally expensive inversion to produce the unmixing matrix and then a second slow step applying that to the data. In the per-cell optimization part of `unmix.autospectral()`, AutoSpectral performs up to 100 such calculations per cell per fluorophore. In other words, for that same set of a million cells in 40 color space, as much as 100 x 40 x 1000000 = 4x10^9 times as many computationally intensive steps. The other reason it's slow is that I am not a computational person. 

There are some things that can be done to improve this. Release v1.0.0 will implement an approach to reduce the search space, somewhere between 10 and 100x, which will help.


## Go Faster

R is not known for its speed.

For faster processing there are three things you can do, hopefully all fairly easy. 

First, upgrade the BLAS and LAPACK libraries used by R. These provide algorithms for linear algebra, which is the heart of spectral unmixing.

On Windows, simply swapping out your .dll files as in this tutorial can give speed ups of 5x.
[Install OpenBLAS](https://github.com/david-cortes/R-openblas-in-windows)
All this involves is downloading the files from the internet, placing them in 
the right folder and doing a quick restart.

On Mac, you can use the vecLib library BLAS that ships with Mac OS as this should be optimized for your system. The following articles may be helpful in setting this as the default BLAS for use in R:
[BLAS for Mac in R](https://cran.r-project.org/bin/macosx/RMacOSX-FAQ.html#Which-BLAS-is-used-and-how-can-it-be-changed_003f)
[Performance BLAS](https://csantill.github.io/RPerformanceWBLAS/)
Feedback from users on Mac who successfully upgrade their BLAS would be appreciated.

Do not set multiple threads for the BLAS as this will conflict with higher
level parallelization, either in AutoSpectral or other packages.

After upgrading the BLAS, you probably need to reinstall `Rcpp` and `RcppArmadillo` to have this compiled with the BLAS.

```{r, eval=FALSE}
install.packages( c( "Rcpp", "RcppArmadillo" ) )
```

Now, install AutoSpectralRcpp. This is fully accessible from R and integrates with AutoSpectral. But, when it gets to the slow bits in the unmixing, it switches over to calculating in C++, so it can be 10-100x faster. Do this after upgrading the BLAS.

[AutoSpectralRcpp](https://github.com/DrCytometer/AutoSpectralRcpp)

You will need [Rtools](https://cran.r-project.org/bin/windows/Rtools/) to compile this.

You can install AutoSpectralRcpp like so:
``` r
devtools::install_github("DrCytometer/AutoSpectralRcpp")
```
Third, turn on parallel processing in AutoSpectral.
*Update*: This is now supported via a `parallel` backend. Importantly, this moves away from `future` and `future_lapply`, which were aborting sometimes on Windows. More usefully, this is a bit faster in many cases, and should support forking via `mclapply` on Mac and Linux systems, which will be much faster. Perhaps most usefully, this appears to allow parallelization of the native R per-cell fluorophore optimization in `unmix.autospectral`, so you should see a nice speed up there.

The parallel processing in AutoSpectralRcpp operates via OpenMP and works well. It is always activated, but the number of threads can be configured.

To activate parallel processing, check the function arguments for a `parallel` option and set it to `TRUE`. Additionally, there is control over the number of threads used, which should be directly in the function call via a `threads` argument. If you don't know how many threads to use, check the recommendation for your machine after running `get.autospectral.param()`:

``` {r, eval = FALSE}
asp$max.worker.process.n
```

Multithreading will always default to this number if you do not explicitly set a number of threads and set `parallel=TRUE`. This is one less than `parallelly::availableCores()`, so it is designed to allow you to keep working on minor stuff while AutoSpectral chugs along in the background.

For unmixing larger data sets, you will do well to use a machine with more CPUs.
Suggestions for faster processing are welcome. Some modest improvements are in 
the works.


```{r dev branch, eval=FALSE}
devtools::install_github("DrCytometer/AutoSpectral@dev")
```

To replace this with the (hopefully) stable version, run this:

```{r master branch, eval=FALSE}
remove.packages("AutoSpectral")
devtools::install_github("DrCytometer/AutoSpectral")
```



## Installation and Runtime

Installation via GitHub should take only a minute or so. It takes less than that on a Dell i7 core laptop.

Occasionally, the help gets corrupted. Just re-install if that happens. If you know why this happens, let me know.

Installation of `AutoSpectralRcpp` will take a couple of minutes because the code needs to compile. You will also first have to install Rtools to have a compiler, and that will take longer, probably 10 minutes or so. Upgrading the BLAS and LAPACK (see below) also takes several minutes if you're taking the time to read the instructions carefully.

Runtime will vary considerably depending on the size and quantity of files you're processing. For the benchmark 42-colour Aurora data set using single-stained cell controls with plenty of data, the slow steps in the pre-processing pipeline are `define.flow.control()` and `clean.controls()`. For the same Aurora dataset on the aforementioned i7 Windows laptop, I get:
* `define.flow.control()` v0.8.7: 12min sequential, 9min parallel
* `define.flow.control()` v0.9.0: 4min sequential, 2min parallel
* `clean.controls()` v0.8.7: 11min sequential, not possible parallel
* `clean.controls()` v0.9.0: 11min sequential, 6.5min parallel, not fully optimized
* `get.spectral.variants()` v.0.8.7: 2min sequential, 1min parallel
* `get.spectral.variants()` v.0.9.0: 65sec sequential, 32sec parallel

Unmixing time depends on the following variable:

* file size (number of cells/events, including debris)
* number of detectors
* number of fluorophores
* unmixing algorithm. OLS and WLS are fast, per-cell AF extraction will be ~50x slower, per-cell fluorophore optimization will be 2-4x slower than per-cell AF when running the "fast" approximation using AutoSpectralRcpp, or about 20-50x slower when using the "slow" exact calculation, again using AutoSpectralRcpp. Using the "fast" approximation in pure R will likely be comparable to or slower than the "slow" method in C++.

Benchmarks for "C3 Lung_GFP_003_Samples.fcs", again on the 8-core laptop, using OpenBLAS and AutoSpectralRcpp, where applicable:

* `unmix.fcs()` WLS or OLS v0.8.7: 9sec
* `unmix.fcs()` WLS or OLS v0.9.0: 9sec
* `unmix.fcs()` WLS or OLS v1.0.0: 
* `unmix.fcs()` perCell AF extraction v0.8.7: 2min
* `unmix.fcs()` perCell AF extraction v0.9.0: 1min
* `unmix.fcs()` perCell AF extraction v1.0.0: 
* `unmix.fcs()` perCell fluorophore optimization "fast" v0.8.7: 9min
* `unmix.fcs()` perCell fluorophore optimization "fast" v0.9.0: <2min
* `unmix.fcs()` perCell fluorophore optimization "fast" v1.0.0: 
* `unmix.fcs()` perCell fluorophore optimization "slow" v0.8.7: 62min
* `unmix.fcs()` perCell fluorophore optimization "slow" v0.9.0: 19min
* `unmix.fcs()` perCell fluorophore optimization "slow" v1.0.0: 
* `unmix.folder()` WLS or OLS, 6 files, v0.8.7: 67sec sequential, interrupted parallel
* `unmix.folder()` WLS or OLS, 6 files, v0.9.0: 62sec sequential, 31sec parallel

Still some work to be done.

